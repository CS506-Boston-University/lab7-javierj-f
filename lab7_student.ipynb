{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\17734\\AppData\\Local\\Temp\\ipykernel_7468\\3103194073.py\", line 1, in <module>\n",
      "    from scipy.stats import pearsonr, spearmanr\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\stats\\__init__.py\", line 606, in <module>\n",
      "    from ._stats_py import *\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py\", line 37, in <module>\n",
      "    from scipy import sparse\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\__init__.py\", line 134, in __getattr__\n",
      "    return _importlib.import_module(f'scipy.{name}')\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\__init__.py\", line 295, in <module>\n",
      "    from ._csr import *\n",
      "  File \"c:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_csr.py\", line 11, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\17734\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pearsonr, spearmanr\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\stats\\__init__.py:606\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    601\u001b[0m \n\u001b[0;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    605\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distance_matrix\n",
      "File \u001b[1;32mc:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\__init__.py:134\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[1;32m--> 134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\17734\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32mc:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\__init__.py:295\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 295\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\17734\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_csr.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _spbase, sparray\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0;32m     12\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upcast\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Pearson vs Spearman Correlation (4 points)\n",
    "\n",
    "## Objective\n",
    "Understand and compare how **Pearson** and **Spearman** correlations measure relationships between variables —  \n",
    "specifically **linear** versus **monotonic** associations — using real-world data from the **World Happiness Report (2024)**.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset: World Happiness Report (2024)\n",
    "\n",
    "This dataset, provided to you from Kaggle, summarizes survey data collected from over 130 countries worldwide.  \n",
    "Each record represents one country and its average well-being score based on multiple social and economic indicators.\n",
    "\n",
    "---\n",
    "\n",
    "### Goal of This Exercise\n",
    "You will:\n",
    "1. Compute and compare **Pearson** and **Spearman** correlations for all predictors with **Ladder score (Happiness)**.  \n",
    "2. Visualize the relationships between happiness and its key factors using **scatterplots with trendlines**.  \n",
    "3. Identify which features show **linear**, **nonlinear**, or **noisy** relationships — where Pearson and Spearman diverge.  \n",
    "4. Interpret the findings to understand when each method should be preferred.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorld-happiness-report-2024.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Basic info\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "url = \"World-happiness-report-2024.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Basic info\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_columns = [\"Ladder score\", \"Log GDP per capita\", 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity','Perceptions of corruption', 'Dystopia + residual' ]\n",
    "df = df[happiness_columns].dropna()\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "sns.pairplot(df[happiness_columns])\n",
    "plt.suptitle(\"Pairwise Relationships among Key Happiness Indicators\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO (Exercise 1.1) (2 points)\n",
    "\n",
    "In this step, you will calculate how strongly each factor is related to **Happiness (Ladder score)** using two correlation methods:\n",
    "\n",
    "1. **Pearson correlation**.  \n",
    "\n",
    "2. **Spearman correlation**.  \n",
    "\n",
    "### Instructions\n",
    "- Use the `.corr()` function in pandas to compute both Pearson and Spearman correlation coefficients.  \n",
    "- Extract only the correlations with **'Ladder score'**.  \n",
    "- Sort the results from highest to lowest to see which factors have the strongest relationship with happiness.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# TODO Implement Pearson and Spearman Correlations\n",
    "# ------------------------------------------------\n",
    "\n",
    "pearson_corr = df.corr(method='pearson')['Ladder score'].sort_values(ascending=False)\n",
    "spearman_corr = df.corr(method='spearman')['Ladder score'].sort_values(ascending=False) \n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "compare = pd.DataFrame({'Pearson': pearson_corr, 'Spearman': spearman_corr})\n",
    "compare = compare.drop('Ladder score', errors='ignore')\n",
    "compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 1.2 – Visualizing Correlations with Regression Plots** (2 points)\n",
    "\n",
    "In this exercise, you will **visualize and quantify the relationships** between key factors and the **Happiness (Ladder score)** using scatter plots and correlation metrics.\n",
    "\n",
    "Each subplot will show how a specific feature (e.g., GDP, life expectancy, social support) relates to happiness, helping you identify both **direction** (positive or negative) and **strength** of association.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "For each feature in `happiness_columns`, calculate two types of correlation with **`Ladder score`**:\n",
    "\n",
    "   - **Pearson correlation** \n",
    "   - **Spearman correlation** \n",
    "\n",
    "*Hint:* Both correlations can be computed using functions from `scipy.stats`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(happiness_columns):\n",
    "    sns.regplot(\n",
    "        data=df,\n",
    "        x=col,\n",
    "        y='Ladder score',\n",
    "        ax=axes[i],\n",
    "        scatter_kws={'alpha': 0.6},\n",
    "        line_kws={'color': 'red'}\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # TODO Implement Pearson and Spearman Correlations\n",
    "    # ------------------------------------------------\n",
    "    pearson_val, _ = pearsonr(df[col], df['Ladder score'])\n",
    "    spearman_val, _ = spearmanr(df[col], df['Ladder score'])\n",
    "\n",
    "    # ----------------------------\n",
    "    # Implementation Ends Here\n",
    "    # ----------------------------\n",
    "    \n",
    "    axes[i].set_title(\n",
    "        f\"{col}\\nPearson = {pearson_val:.2f}, Spearman = {spearman_val:.2f}\",\n",
    "        fontsize=10\n",
    "    )\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"Ladder score\")\n",
    "\n",
    "# Adjust layout and title\n",
    "plt.suptitle(\"Happiness (Ladder Score) vs Key Predictors\", fontsize=14, y=1.02)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Simpson’s Paradox (6 points)\n",
    "\n",
    "## Objective\n",
    "Understand **Simpson’s Paradox** — a situation where a trend appears in aggregated data but reverses or disappears when the data are divided into groups.\n",
    "\n",
    "You’ll explore this paradox using the **World Happiness Report (2024)** dataset, by analyzing the relationship between **GDP per capita** and **Happiness**, both overall and within different **world regions**.\n",
    "\n",
    "---\n",
    "\n",
    "**Example idea:**  \n",
    "\n",
    "Globally, countries with higher GDP have higher happiness.  But within each region, that relationship might weaken or even reverse.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"World-happiness-report-2024.csv\")\n",
    "df = df.dropna()\n",
    "# df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 2.1 – Global Relationship: GDP vs Happiness** (3 points)\n",
    "\n",
    "In this exercise, you will focus on a single predictor — **Log GDP per capita** — to explore its global relationship with **Happiness (Ladder score)**.  \n",
    "You will calculate the correlation between these two variables and visualize their linear trend.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "**Compute both correlation coefficients** between `Log GDP per capita` and `Ladder score`:\n",
    "\n",
    "   - **Pearson correlation** \n",
    "   - **Spearman correlation**\n",
    "\n",
    "*Hint:* You can find both correlation functions in `scipy.stats`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TODO Implement Pearson Spearman Correlations for predictor Log GDP per capita\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "pearson_global, _ = pearsonr(df['Log GDP per capita'], df['Ladder score'])\n",
    "spearman_global, _ = spearmanr(df['Log GDP per capita'], df['Ladder score'])\n",
    "print(f\"Global Pearson correlation (GDP vs Happiness): {pearson_global:.2f}\")\n",
    "print(f\"Global Spearman correlation (GDP vs Happiness): {spearman_global:.2f}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.regplot(data=df, x='Log GDP per capita', y='Ladder score', color='red', scatter_kws={'alpha':0.6})\n",
    "plt.title(\"Global Relationship: GDP vs Happiness\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 2.2 – Regional Correlations: GDP vs Happiness** (3 points)\n",
    "\n",
    "In this exercise, you will analyze how the relationship between **Log GDP per capita** and **Happiness (Ladder score)** varies **across regions**.  \n",
    "This helps you understand whether the global GDP–Happiness trend is consistent or differs regionally.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "1. **Group the data by region** using the column `Regional indicator`.\n",
    "\n",
    "2. **Within each region**, compute the **Pearson correlation** between:\n",
    "   - `Log GDP per capita`\n",
    "   - `Ladder score`\n",
    "\n",
    "\n",
    "Hint - Use: pearsonr from scipy.stats\n",
    "\n",
    "*Another Hint:* You can follow these steps to compute the correlation by region:\n",
    "\n",
    "1. **Group the data** by `Regional indicator` using the `groupby()` method.  \n",
    "2. **Within each group**, calculate the correlation between `Log GDP per capita` and `Ladder score` using a correlation function such as `pearsonr` from `scipy.stats`.  \n",
    "3. **Extract the correlation value** (the first element returned by `pearsonr`).  \n",
    "4. **Sort the results** to identify which regions show the strongest positive or negative relationships.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# TODO Implement Pearson Spearman Correlations for predictor Log GDP per capita by region\n",
    "# ----------------------------------------------------------------------------------------\n",
    "regional_corr = (\n",
    "    df.groupby('Regional indicator')\n",
    "    .apply(lambda x: pearsonr(x['Log GDP per capita'], x['Ladder score']))\n",
    "    .sort_values(ascending=False) \n",
    "    .to_frame(name='Pearson Correlation')\n",
    "                 \n",
    ")\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "print(\"Regional Pearson correlations (GDP vs Happiness):\")\n",
    "display(regional_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unique regions\n",
    "regions = df['Regional indicator'].unique()\n",
    "num_regions = len(regions)\n",
    "\n",
    "# Determine grid size automatically\n",
    "ncols = 3\n",
    "nrows = (num_regions + ncols - 1) // ncols\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, region in enumerate(regions):\n",
    "    sub = df[df['Regional indicator'] == region]\n",
    "\n",
    "    # Compute regional Pearson correlation\n",
    "    pearson_val, _ = pearsonr(sub['Log GDP per capita'], sub['Ladder score'])\n",
    "\n",
    "    sns.regplot(\n",
    "        data=sub,\n",
    "        x='Log GDP per capita',\n",
    "        y='Ladder score',\n",
    "        ax=axes[i],\n",
    "        scatter_kws={'alpha':0.6, 's':50},\n",
    "        line_kws={'color':'red'}\n",
    "    )\n",
    "    \n",
    "    axes[i].set_title(f\"{region}\\nPearson r = {pearson_val:.2f}\", fontsize=10)\n",
    "    axes[i].set_xlabel(\"Log GDP per capita\")\n",
    "    axes[i].set_ylabel(\"Ladder score\")\n",
    "\n",
    "# Remove unused subplots if regions < grid size\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.suptitle(\"Simpson’s Paradox: GDP vs Happiness by Region\", fontsize=14, y=0.98)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Digital Wellbeing and Happiness Prediction Using Decision Trees (14 points)\n",
    "\n",
    "### Objective: Learn how to apply **Decision Trees** for **classification tasks** using a real-world dataset on digital wellbeing. You will explore how behavioral factors like screen time, sleep quality, stress, and exercise relate to happiness and train decision tree models using different splitting criteria.\n",
    "\n",
    "> **How can we tell which features matter and whether the model is good — without consulting an oracle?**\n",
    "\n",
    "---\n",
    "\n",
    "### **Focus Areas**\n",
    "\n",
    "1. **Feature Importance**\n",
    "   - Examine which variables the Decision Tree considers most influential.\n",
    "\n",
    "2. **Model Evaluation Without an Oracle**\n",
    "   - Evaluate metrics such as **accuracy**, **precision**, **recall**, and **F1-score**.\n",
    "   - Review the **confusion matrix** to understand where the model succeeds or fails.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load Dataset\n",
    "\n",
    "df = pd.read_csv(\"Mental_Health_and_Social_Media_Balance_Dataset.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# Drop ID column (non-informative)\n",
    "df = df.drop(columns=[\"User_ID\"])\n",
    "\n",
    "#Create Target Variable\n",
    "# Happy (>=8) → 1, Unhappy (<8) → 0\n",
    "df[\"Happiness_Status\"] = np.where(df[\"Happiness_Index(1-10)\"] >= 8, 1, 0)\n",
    "\n",
    "# Drop the original happiness index to avoid leakage\n",
    "df = df.drop(columns=[\"Happiness_Index(1-10)\"])\n",
    "\n",
    "# Encode Categorical Variables\n",
    "\n",
    "categorical_cols = [\"Gender\", \"Social_Media_Platform\"]\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "df_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.1 – Feature Correlation with Happiness Status** (2 points)\n",
    "\n",
    "In this exercise, you will compute how strongly each encoded feature is related to **Happiness_Status** (binary classification: Happy vs Unhappy).  \n",
    "You will use two correlation methods to capture both linear and rank-based relationships between predictors and happiness.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "1. **Work with the encoded dataset** `df_encoded`, which includes numerical and categorical variables converted into numeric form.\n",
    "\n",
    "2. **Compute correlation coefficients** between each feature and the target variable `Happiness_Status` using:\n",
    "   - **Pearson correlation** on Happiness_Status\n",
    "   - **Spearman correlation** on Happiness_Status\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# TODO Implement Pearson and Spearman Correlations\n",
    "# ------------------------------------------------\n",
    "\n",
    "pearson_corr = df_encoded.corr(method='pearson')['Happiness_Status'].sort_values(ascending=False)\n",
    "spearman_corr = df_encoded.corr(method='spearman')['Happiness_Status'].sort_values(ascending=False)\n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "compare = pd.DataFrame({'Pearson': pearson_corr, 'Spearman': spearman_corr})\n",
    "compare = compare.drop('Ladder score', errors='ignore')\n",
    "compare\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.2 – Splitting the Dataset into Training and Testing Sets** (2 points)\n",
    "\n",
    "In this exercise, you will split your encoded dataset into **training** and **testing** subsets to prepare for model building.  \n",
    "This ensures that you can train your model on one portion of the data and evaluate its performance on unseen data, avoiding overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "Use sklearn train_test_split\n",
    "   ```python\n",
    "   from sklearn.model_selection import train_test_split \n",
    "\n",
    "   params := (X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_encoded.drop(\"Happiness_Status\", axis=1)\n",
    "y = df_encoded[\"Happiness_Status\"]\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# TODO Slipt your dataset into Train and Test using sklearn train_test_split\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y                                                  \n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.3 – Building Decision Trees with Different Splitting Criteria** (4 points)\n",
    "\n",
    "In this exercise, you will train and evaluate **Decision Tree classifiers** using three different impurity measures:\n",
    "- **Gini Index**\n",
    "- **Entropy**\n",
    "- **Log Loss**\n",
    "\n",
    "The goal is to compare how each criterion affects the model’s performance and decision boundaries.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "1. For each criterion (`\"gini\"`, `\"entropy\"`, and `\"log_loss\"`), build and train a Decision Tree model using the training data.  \n",
    "2. Evaluate each model on the test set and record the **accuracy score**.  \n",
    "3. Use random_state = 42. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "criteria = [\"gini\", \"entropy\", \"log_loss\"] \n",
    "results = {}\n",
    "\n",
    "for c in criteria:\n",
    "    # --------------------------------------------------------------------------\n",
    "    # TODO Implement Decision Trees for all the three criterion mentioned above\n",
    "    # --------------------------------------------------------------------------\n",
    "    clf = DecisionTreeClassifier(criterion=c, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    # ----------------------------\n",
    "    # Implementation Ends Here\n",
    "    # ----------------------------\n",
    "    results[c] = {\"model\": clf, \"accuracy\": acc}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Criterion: {c.upper()}\")\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Unhappy\", \"Happy\"]))\n",
    "    \n",
    "    # Confusion matrix visualization\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=[\"Unhappy\", \"Happy\"],\n",
    "        cmap=\"Blues\",\n",
    "        values_format=\".0f\"\n",
    "    )\n",
    "    plt.title(f\"Confusion Matrix ({c.upper()} Criterion)\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.grid(False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.4 – Exploring Decision Tree Hyperparameters** (4 points)\n",
    "\n",
    "In this exercise, you will explore how **Decision Tree performance** changes with different model configurations.  \n",
    "You’ll systematically vary three parameters — **splitting criterion**, **maximum depth**, and **minimum samples required to split** — to observe their effect on accuracy and F1-score.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "1. **Loop over multiple configurations:**\n",
    "   - Use the following lists for testing:\n",
    "     - `criteria = ['gini', 'entropy', 'log_loss']`\n",
    "     - `depth_values = [4, 6, 8, 10]`\n",
    "     - `min_samples_split = [2, 5, 10, 20]`\n",
    "\n",
    "2. For each combination:\n",
    "   - Build and train a **DecisionTreeClassifier** using the specified parameters.  \n",
    "   - Use random_state = 42 for the classifier\n",
    "   - Evaluate its performance on the test data.\n",
    "\n",
    "3. **Compute and record metrics:**\n",
    "   - **Accuracy** – overall prediction correctness.  \n",
    "   - **F1 Score** – balance between precision and recall.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    ConfusionMatrixDisplay, classification_report\n",
    ")\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "depth_values = [4, 6, 8, 10]\n",
    "min_samples_values = [2, 5, 10, 20]\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "records = []\n",
    "\n",
    "for crit in criteria:\n",
    "    for max_depth in depth_values:\n",
    "        for min_split in min_samples_values:\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "            # TODO Implement Decision Trees for all the three criteria, depth_values and min_sample_values\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "            clf = DecisionTreeClassifier(\n",
    "                criterion=crit,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_split=min_split,\n",
    "                random_state=42\n",
    "            ) \n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "            # TODO Compute Accuracy and F1 scores\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # ----------------------------\n",
    "            # Implementation Ends Here\n",
    "            # ----------------------------\n",
    "            records.append({\n",
    "                \"Criterion\": crit,\n",
    "                \"Max Depth\": max_depth,\n",
    "                \"Min Samples Split\": min_split,\n",
    "                \"Accuracy\": acc,\n",
    "                \"F1 Score\": f1,\n",
    "                \"Model\": clf\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(records)\n",
    "\n",
    "# Display neatly sorted table\n",
    "display(\n",
    "    results_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .style.background_gradient(subset=[\"Accuracy\", \"F1 Score\"], cmap=\"YlGn\")\n",
    "    .format({\"Accuracy\": \"{:.3f}\", \"F1 Score\": \"{:.3f}\"})\n",
    "    .set_caption(\"Decision Tree Performance Across Hyperparameters\")\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.5 – Evaluating and Interpreting the Best Decision Tree Model** (2 points)\n",
    "\n",
    "In this exercise, you will identify the **best-performing Decision Tree model** from all tested hyperparameter combinations and evaluate it using multiple performance metrics and visualizations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "**Compute model performance metrics:**\n",
    "   - Calculate and print using sklean packages on y_test, y_pred_best:\n",
    "     - **Accuracy**\n",
    "     - **Precision**\n",
    "     - **Recall**\n",
    "     - **F1 Score**\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = results_df.loc[results_df[\"Accuracy\"].idxmax()]\n",
    "best_model = best_row[\"Model\"]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"BEST MODEL FOUND\")\n",
    "print('='*70)\n",
    "print(f\"Criterion          : {best_row['Criterion'].upper()}\")\n",
    "print(f\"Max Depth          : {best_row['Max Depth']}\")\n",
    "print(f\"Min Samples Split  : {best_row['Min Samples Split']}\")\n",
    "print(f\"Accuracy           : {best_row['Accuracy']:.3f}\")\n",
    "print(f\"F1 Score           : {best_row['F1 Score']:.3f}\")\n",
    "print('='*70)\n",
    "\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# TODO Compute Accuracy, F1, recall and precision scores on y_test and y_pred_best\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_best)\n",
    "prec = precision_score(y_test, y_pred_best)\n",
    "rec = recall_score(y_test, y_pred_best)\n",
    "f1 = f1_score(y_test, y_pred_best)\n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\nClassification Metrics Summary\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Accuracy       : {acc:.3f}\")\n",
    "print(f\"Precision      : {prec:.3f}\")\n",
    "print(f\"Recall         : {rec:.3f}\")\n",
    "print(f\"F1 Score       : {f1:.3f}\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=[\"Unhappy\", \"Happy\"]))\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    best_model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=[\"Unhappy\", \"Happy\"],\n",
    "    cmap=\"Purples\",\n",
    "    values_format=\".0f\"\n",
    ")\n",
    "plt.title(\n",
    "    f\"Confusion Matrix - Best Model ({best_row['Criterion'].upper()} | Depth={best_row['Max Depth']} | MinSplit={best_row['Min Samples Split']})\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\"\n",
    ")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "importances = pd.Series(best_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances.values, y=importances.index, palette=\"mako\")\n",
    "plt.title(\n",
    "    f\"Feature Importance - Best Model ({best_row['Criterion'].upper()})\",\n",
    "    fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ## Save the Decision Tree of the Best Model as PNG\n",
    "\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identify the best-performing model\n",
    "best_criterion = max(results, key=lambda c: results[c][\"accuracy\"])\n",
    "best_model = results[best_criterion][\"model\"]\n",
    "\n",
    "print(f\"\\nBest performing model: {best_criterion.upper()} (Accuracy = {results[best_criterion]['accuracy']:.3f})\")\n",
    "\n",
    "# Create a large, high-resolution figure\n",
    "fig = plt.figure(figsize=(60, 20))  # adjust for longer arrows and more spacing\n",
    "tree.plot_tree(\n",
    "    best_model,\n",
    "    feature_names=X.columns,\n",
    "    class_names=[\"Unhappy\", \"Happy\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=8,\n",
    "    proportion=True\n",
    ")\n",
    "\n",
    "# Save as high-resolution PNG\n",
    "output_path = f\"decision_tree_best_{best_criterion}.png\"\n",
    "fig.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.close(fig)\n",
    "print(f\"Saved best model tree as: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 4: Questions and Answers** (10 points)\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Correlation vs. Causation**  \n",
    "In the World Happiness dataset, both Pearson and Spearman correlations show strong relationships between GDP and Happiness.  \n",
    "- Why does a high correlation *not necessarily* imply that higher GDP causes higher happiness?  \n",
    "- What factors could confound this relationship?\n",
    "\n",
    "**Answer:** We essentially isolated one of the factors out of the many sampled and found that it fit our hypothesis. We also see similar trends with life expectancy, social support, and freedom to make life choices. These are things not necessarily affected by GDP but that also affect happiness.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Simpson’s Paradox**  \n",
    "When you analyzed GDP vs. Happiness by region, how did the direction or strength of correlation change compared to the global trend?  \n",
    "- What does this reveal about the importance of analyzing data within subgroups?\n",
    "\n",
    "**Answer:** The global trend shows a strong correlation between GDP and happiness. However, when isolated by regions, we see that this trend does not necessarily apply. This means that is important to study subgroups as lumping them all together may skew the data towards one conclusion that is not indicative of the subgroups alone. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Which model is the best, based on splitting criterion**  \n",
    "- Which **splitting criterion** (Gini, Entropy, or Log Loss) produced the **best accuracy** in your experiment? Specify the **hyperparameters** (`max_depth` and `min_samples_split`) that gave the highest accuracy.  \n",
    "\n",
    "**Answer:** Based on the splitting criterion, log_loss was the most accurate model with hyperparameters:\n",
    "\n",
    "DecisionTreeClassifier(criterion='log_loss', max_depth=6, min_samples_split=5, random_state=42)\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Which model is the best?**  \n",
    "- According to the **feature importance plot**, which variable had the **greatest influence** on predicting happiness?  \n",
    "- Does this result match your **intuition** about which behaviors (e.g., screen time, sleep, stress, exercise) most affect happiness?  \n",
    "\n",
    "**Answer:** The most important feature in our plot was Daily Screen Time. I can see how this would be the most important feature as people who are generally unhappy would isolate themselves and thus spend more time on screens, limiting their mobilty and in-person social interaction.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Tree Interpretability**  \n",
    "- Why are **Decision Trees** considered **interpretable models**?  \n",
    "- What are some **limitations** of that interpretability when trees become deeper or more complex?\n",
    "\n",
    "**Answer:** Decision trees are interpretable because they essentially emulate reasoning via a series of conditional statements that create a path to follow. However, as they become more complex, we lose some of that simplicity and it essentially defeats the purpose of a traceable structure.\n",
    "\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
